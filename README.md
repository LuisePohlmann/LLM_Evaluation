# LLM Evaluation

## Project Description

As large language models are increasingly used to make life-changing decisions, it has become more important to check in which ways these models are biased. This paper compares three language models on their performance on cleaned, criticized, and control subsets of the race/color category of the CrowSPairs challenge set. Building on previous criticism of CrowSPairs, the goal is to evaluate whether the CrowSPairs dataset is a suitable benchmark for measuring racial bias and how biased the models ALBERT, T5-small, and DistilGPT-2 are. Results show that DistilGPT-2 is the best performing model on all three subsets. However, all models perform worse on the cleaned dataset, suggesting that the shortcomings of the CrowSPairs dataset obfuscate how biased language models truly are. Future work in designing challenge datasets for measuring bias should take a fundamentally different approach to CrowSPairs.

## Usage
To perform the analysis run `Lamore_Project_Notebook_Pohlmann_Luise.ipynb`. For further information on the CrowSPairs Dataset run `CrowSPairs_notebook-upload.ipynb`.

## License
Copyright (c) 2026 Luise Pohlmann




